---
title: "Open data (epilogue): Some lessons learned"
author: "Leo Kiernan"
date: "2023-02-20"
image: OS uk rivers.png
draft: false
toc: true
format: 
  html:
    code-fold: true
categories: [code, analysis, opendata, OS]
---

# Overview

I'm drawing to a close this set of posts on #OpenData. Thus-far I've published four posts:

-   [Part 1](https://leo037.quarto.pub/leos-blog/posts/opendata%20thamesEDM/opendata%20thamesEDM.html) of the series explored an open data-set on [Event Discharge Monitors](https://www.thameswater.co.uk/about-us/performance/river-health) (EDMs) recently made accessible by *Thames Water.*

-   [Part 2](https://leo037.quarto.pub/leos-blog/posts/opendata_EA/opendata_EA.html) of the series explored data on English river levels and flows from the [UK Environment Agency](https://www.gov.uk/government/organisations/environment-agency) (EA)

-   [Part 3](https://leo037.quarto.pub/leos-blog/posts/opendata_UK_rivers/opendata_UK_rivers.html) of the series explored the rivers themselves made available from: [OS Open Rivers - data.gov.uk](https://www.data.gov.uk/dataset/dc29160b-b163-4c6e-8817-f313229bcc23/os-open-rivers).

-   [Part 4](https://leo037.quarto.pub/leos-blog/posts/rivers_edms_levels/exploration_of_rivers_and_discharges.html) described how I pulled together all three #OpenData sets into an online application ([you can use the application by clicking here](https://drleo037.shinyapps.io/openRivers/)). The app allowed the user to check *any* point on *any* river, the app would then highlight any EDMs that were discharging sewage upstream from that point on the river. The app also visualised the EDM discharges (published by Thames Water) in the context of river loadings (as evidence from the EA #OpenData API).

Throughout these posts I've only done minimal work to check and cleanse the data. There's a long list of questions that arose as I loaded and processed the datasets.

-   The Thames water API is simple and clean. It delivers everything one might need to replicate their on-line map. The pre-requisite of registering for the service has benefits (such as notifications from Thames Water when updates and outages. However, the requirements to use (and keep secret) client IDs and tokens when collecting data, and the restrictions in the terms of service make publishing of third-party apps that show live data more complicated than might be otherwise. For example, when I was writing the shiny interactive app, I was not able to add a "get latest data" button that would collect data from the Thames API as I was concerned this would breach the terms which state that users must not "allow any other person to access this API using your login details". Hence, to download data I have had to add a step by which one must enter credentials to collect data from the API.
-   The Thames Water API offers two endpoints, one for live data, another for historic discharge events. As explored in the first post in this series, the context of the data returned from the historic end-point could be explained. I struggled to reverse-engineer what the data represented (particularly the "Offline start" and "Offline stop" alert status'). This lead to my summary of this dataset being inconclusive, ambiguous and potentially incorrect. Finally, improved documentation would not be quite enough to release full value from the historic end-point. Because the historic EDM status data only contains status changes, and is limited to only include status changes since 2022-04-01 it is not currently possible to fully reconstruct that state of all EDMs, even during the date-ranges supported by the API. If I could request one extra piece of information, it would be something that would summarise the (initial) state of EDMs from which, subsequent state changed could be tracked.
-   Even though I have some minor observations on the data shared by Thames Water, making the data available is a brave and constructive step. Presumably, Thames Water are open to feedback on the API and may adapt this resource in the future to improve the experience of the consumer. This resource is already industry leading, and with a few small tweaks it would be excellent.

# Things I've not done that perhaps I should have...

## Thinks I just couldn't walk away from once they'd surfaced

When I began this "epilogue" write-up I had only explored the "live" endpoints for the EA and EDM APIs. The list of things I began to write up here included:

1.  "accessing historic data from EDM and EA APIs"

2.  "handling apparent disconnections in the Ordnance Survey rivers dataset that limit my ability to search upstream for discharges into rivers.

The more I began to explain these here, the more I just wanted to face into them. After all, the point of this series was to explore opendata. Eventually I buckled, gave in to "scope creep". It took me on a longer that expected journey into reshaping, big(ish) data-processing and graph-augmentation. None of which I regret in any way.

I have revisited [post one](https://leo037.quarto.pub/leos-blog/posts/opendata%20thamesEDM/opendata%20thamesEDM.html) and [post two](https://leo037.quarto.pub/leos-blog/posts/opendata_EA/opendata_EA.html) and [post three](https://leo037.quarto.pub/leos-blog/posts/opendata_UK_rivers/opendata_UK_rivers.html), adding sections the extra steps. I've signposted the new content at the top of each post for those that read them when they were initially published. To cut a long story short, both Thames Water and the EA publish enough detail on discharges and river levels for both to be analysed together over time, and there are a few steps that can be taken to significantly improve the connectivity of river network for tracing purposes.

## Things that sill not done

There are still plenty I should have done but haven't. These include:

-   **(not) good enough practices:** I've cut a few coding corners while writing these posts. Sure, I should have embedded all of them into my day-to-day by now, but I'll put all that on the "opportunities for self improvement" stack along with actually learning French, and touch-typing properly. I'm blaming my indiscretions on a mixture of the added overheads here of learning how to bog & publish apps (there's a first time for everything), and utter denial that I was ever going to do either. To be fair, I don't think I'm that far off. If I started, I'd end up re-factoring a load of code en-route. I've build up probably a few days of technical debt I'm walking away from by not doing some things when I should've and not fixing them now.

-   **Better practices:** This is obviously a great opportunity to highlight what I *should* have done throughout. I refer the interested reader to a wonderful set of resources modestly titled "**Good Enough Practices for Scientific Computing**" available [online here](http://swcarpentry.github.io/good-enough-practices-in-scientific-computing/) (with [pdf version here](https://arxiv.org/abs/1609.00037)). *Aside:* I am beginning to wonder how many of these tips can be retrospectively documented by the emerging generations of AI. For example, documenting functions (I'm sure chatGPT can help here! I have used it to comment the asHTML() function in post 2). Some people are already using GPT4 to write code and even generate web apps from sketches drawn on.

# Summary

To summarise, in this post:

-   I have explored a geospatial open dataset provided by the Ordnance Survey. The dataset is great, but has the usual limitation and caveats, especially around completeness of the names of river segments. The coordinates of the river segments look great and will no doubt, come in handy if one were to join this data spatially to other datasets.

-   I have use the connectivity defined in the dataset to build a topological (graph / network) representation of the rivers. This allows virtual navigation around the rivers.

-   I have used the topological rivers to route-find along rivers and to group rivers in to river systems. As with the geospatial attributes, the logical connectivity will be useful in subsequent analysis.

# Where next?

As per previous posts... It's over to you if you wish to continue exploration of the data and find ways to visualize, summarize and generate insight. *The OS open-rivers* open data-set is downloadable and can be manipulated quite simply using the great FOSS toolkits. I hope this post has been interesting. I look forward to other people's apps, posts and summaries of this valuable open data-set.

Personally, I will continue to explore this data, creating visuals and joining it to other open data-sets, but that is for another post...
