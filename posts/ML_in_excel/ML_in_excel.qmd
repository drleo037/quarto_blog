---
title: "Machine Learning in Excel?"
author: "Leo Kiernan"
date: "2023-04-03"
image: AI_ifthen.jpg
draft: true
toc: true
format: 
  html:
    code-fold: true
categories: [code, analysis, excel, ML, AI, LM, randomForests, classification, regression]
---

delme

```{r}
library(tidyverse)
data_df <- iris
iris_n_noise <- iris %>%
  as_tibble() %>%
  add_column (Noise = runif (nrow (.))) %>%
  add_column (other_noise = runif (nrow (.))) %>%
  mutate(Noisy.Sepal.Length = Sepal.Length + 10.0*other_noise) %>%
  select(-other_noise)
# data_df <- iris_n_noise

df_split <- rsample::initial_split(data_df) # note: stratify by Species
df_train <- rsample::training(df_split)
df_test  <- rsample::testing(df_split)
data_df  <- df_train

model_clas <- ranger::ranger(Species ~ ., 
                     data = data_df,
                     num.trees = 2,
                     importance = "impurity"
)
as.character(tidypredict::tidypredict_fit(model_clas)[1]) # DPLYR

pred.iris <- predict(model_clas, data = data_df)
table(data_df$Species, pred.iris$predictions)

levels(iris$Species) == levels(data_df$Species)
```

# Overview

Can you access Machine Learning in Excel? Read on, this post is dedicated to finding out! On route I hope to demystify some of the most popular and powerful Machine Learning methods of recent years and end up with something that anyone with access to a spreadsheet can use for regression or classification tasks (just so long as they're not too big).

In truth, this post was inspired by the following meme:

![](/posts/ML_in_excel/AI_ifthen.jpg)

This image makes me laugh for many reasons.

-   On the one hand, life isn't that simple! Artificial Intelligence (AI) is a huge field that spans from experts systems with fixed and well-defined inference logic through to the almost impenetrable (but extremely useful\|) transforms crafted from data by Machine Learning (ML) paradigms.

-   On the other hand, the image summarises (maybe overly so) a considerable branch of AI and ML. You will find IF-THEN rules in some of the earliest and most recent forms of AI. They underpinned the Expert Systems that emerged in the 1970 and still underpin some of the most successful recent forms of ML.

It's the simplicity and clarity (practicality) that is lovingly mocked in the meme that has allowed the humble "IF THEN" to have survived for 50 years in a technical field that is so fluid.

OK, so history tells us that IF-THEN *is* a credible tool for AI and ML. The Microsoft documentation says that Excel has an IF (this, then-that, otherwise-the-other). So **the door is open**! Note: Excel also has many other logic manipulation functions that I'm not going to touch here but are worth noting, like SWITCH, CHOOSE, and the invaluable and overly used LOOKUP family and INDEX+MATCH). It also has some very powerful ways to search for solutions. If you're not aware, I encourage you to search "goal seek" and "solver" add-ins (bundled with Excel). These are underpinned by a powerful generalised gradient descent algorithms and can answer all sorts of business questions right out of the box through a form of "learning" (fitting / calibration / solving / optimising).

## Introducing some ML concepts

Before getting all technical, I'd like to introduce some of the terms I'll rely on in this post. If you're already verse in decision trees and random forests feel free to skip. If you're genuinely interested in how they work please dig deeper than my description here, I'm just trying to get some big-picture concepts in place as context for the rest of this post.

-   **Decision Trees**: Decision Trees are just a nested sequence of IF-THEN logic. They're quite intuitive. The reason why they're called decision trees is because the help you make decisions and look like trees (The logic shown in the meme show branching conditions that makes it look like a 'tree'). For example, a really small decision tree for 'going out safely' might be:

    -   <div>

        > -   IF \[it's raining\] THEN {bring your umberella}
        >
        > -   ELSE...
        >
        >     -   IF \[it's sunny\] THEN {wear sunscreen}
        >
        >     -   ELSE {you're good to go!}

        </div>

    Note: In the above example, each pair of IF-ELSE generate '**branches**' as the decision can go two ways depending on the result. Moving along the sequence of questions moves along a specific combination of branches until there are no more questions left to answer. At this point we have tested all the conditions and we can take some action. The bits I've put in {curly brackets} are the actions, because they are at the end of the branches they are called '**leaf**' nodes. The leaf {wear sunscreen} is the action to take IF \[it's not raining\] AND \[it's sunny\]

    You could imagine improving this tree in many ways... You could add all sorts of logic to make the task of "going out safely" more complete (e.g. IF \[it's raining\] THEN IF{it's going to stop soon} THEN \[wait a bit\] ELSE {bring your umbrella} etc.)

-   **Machine learning and decision trees**: It's easy for people to define rules for simple trees but not so easy for complex situations, especially those that are not based on something we already understand. ML decision trees come in to play when we have examples of desired outcomes coupled to a bunch of evidence upon which an outcome can be based. The magic that has been brought by the ML community is *how* to build decisions trees under these circumstances. There's loads of material on this on-line. I'd point to a great 10 minute video of a guy explaining all of this [here](https://www.youtube.com/watch?v=LDRbO9a6XPU&t=592s).

-   **Random Forests**: At the highest level, random forests are just collections of Decision Trees. Each tree is built using the same learning rules as the next one. If you're wondering why it's useful to have many trees, it's because many trees bring with them different perspectives on the data. Often each tree is built using a sub-set of the data, either by limiting the aspects of the evidence (dimensions) or by limiting the examples (rows). Any one tree may be limited in one way or another, but by combining many trees the weaknesses of any single tree begin to diminish. It's analogous to asking for a second opinion, or in the extreme, "the wisdom of the masses". There's a good article [here](https://towardsdatascience.com/random-forests-walkthrough-why-are-they-better-than-decision-trees-22e02a28c6bd) about just that. Also some good intuition can be gathered from this [blog post](https://towardsdatascience.com/why-random-forests-outperform-decision-trees-1b0f175a0b5). Obviously, if you use random forests you may get many different answers for the same question. The ML community have also resolved this, so perhaps if you're looking for a number (i.e. you're regressing) you might chose the average (mean) of all the possible options. Or if you're looking for a label (as per the 'name the fruit' example in that you-tube video) you may chose to go with the most popular (modal) result.

In summary... decision trees and random-forests are strewn with IF-THEN logic.

## Sanity check

Pausing for a moment, before diving any further into a post that considered Machine learning and Excel...Another internet meme springs into the mind at this point:

![](but_why_should_you.JPG)

I'm not sure I'll ever be able to answer the question "but... why?" other than by making three statements (with the usual disclaimers around 'The postings on this site are my own and do not necessarily reflect the views of \[Employer\].' etc.)

-   That scooby-doo meme started an itch I had to scratch. Surely decision trees can be delivered in excel

-   (personal development) The journey of trying to drop ML like random forests into Excel helps to demystify ML and brings challenges that were sufficiently non-trivial to feel worthwhile.

-   Finally, and probably most significantly: ML is useful and Excel is ubiquitous, they rarely overlap, is there value in bridging the gap between the two? Builds bridges between the two communities may increase tolerance or reduce friction between the two. The reduction of corporate silos can lead to all sorts of innovations... who knows, maybe ML can be delivered in Excel. Maybe Excel users will become open to alternative ways to analyse data. There's a great video that's well worth a watch exploring such things from JD Long [here](https://www.youtube.com/watch?v=CjNOSrfQiAY).

Most of the rest of this post focusses on build ML models (for both classification and regression) and then how to get these models into excel. however I will need to build these models on *something*. so there's also a lead-in section exploring the data on which I'll be building the models. I'd recommend reading this section even though it's not directly about ML or Excel. It will give some insight into what it takes to make good classification and regression models and contextualise the content of the other sections.\

## Machine Learning in databases.

Even though I'm preoccupied in this post with getting to the point where ML models can be executed in excel, the keen-eyed will notice that as part of the journey I will move through a stage where the ML models are available as SQL. Obviously some people would quite happily disembark at the point where ML models are available as SQL and can be deployed within the databases of choice. Furthermore, there's plenty of options that can build and deploy ML in-database without even extracting the underlying data.

# The data that I'll be modelling (optional)

For this post I've chosen a dataset called "Iris". It's one of those "hello world" that is small, but it's well understood and can be used to expo ML for both regression *and* classification. The methods I'm exploring work for larger datasets (more fields and more examples). I'll make some observations on the limits of applying ML in Excel towards the end of this blog.

As ever, before I get started I'm going to load some libraries that I'll be using throughout this post[^1].

[^1]: In general you may not know up-front what packages you need. packages come into play ask you move through the various phases of load-explore--model-summarise-export. The list of packages has got longer as I've attempted more and more steps in this post. I could've loaded each library at the point I need them in the code (or references them using {package}::{function} as per the stringi example in one of my functions) but I've chosen to load them all up-front just as a convention.

```{r load libraries, warning=FALSE, message=FALSE}
library(magrittr)
library(tidyverse)
```

## Introducing the dataset I'll be using throughout

I'm using a dataset called 'iris' in this post because it's simple, available and can be used for either classification or regression. It contains 150 examples of measurements taken from different types of iris. Each row is an example of a single iris from one of three species. The dataset holds statistics on each iris like the length and width of sepals and petal.

The table below shows the first 5 rows of the iris dataset

```{r quick look at iris }
head(iris, 5)
```

We can see that there are five things measured on each iris (each row of the dataset). There are four numeric measurements (**length** and **width** of **sepals** and **petals**) and one categorical (factor) describing the **species** of the iris.

I am going to do two kinds of modelling:

-   Classification: I am going to learn how to tell the **species** of an iris based on the size of the petal and sepals[^2]

-   Regression: I'm going to learn how to estimate the **length of the petals** based on the species and other attributes.

[^2]: The dataset is relatively simple to feed into a classifier because the classes (species) are 'balanced' (which just means there's the same number of examples in each class). The ML community have developed plenty of ways that to handle unbalanced classes but anyone undertaking ML classification must consider this when constructing any ML solution.

## Making the data a little more interesting

In some ways, the iris dataset is a little too clean to highlight anything interesting about the machine learning process... So I'm going to add two extra columns (measurements) to each iris to see if/how the ML algorithms decide to use these in the classification and regression tasks:

-   **Noise**: Noise will be entirely random, unrelated to the characteristics of each iris in any way. I'll use this as a test of the algorithms. Because the number is unrelated to the iris it should have no predictive power to help me classify species or estimate petal length, so it shouldnt be included in the decision making processes.

-   **Noisy.Sepal.Length**: This is a *little* related to an attribute of each iris. It's like the measurement of the length of the sepal but taken in a really sloppy way where it's the true length but with a random number added or subtracted to make the measurement almost useless. This can never be as useful as the clean version of Sepal.Length, but compared to **Noise**, this measure contains *some* value.

```{r augment the iris dataset with some useless and nearly uesless extra columns}
# iris_n_noise ----
# create (augment) the dataset we'll be using through this piece
iris_n_noise <- iris %>%
  add_column (Noise = runif (nrow (.))) %>%
  add_column (other_noise = runif (nrow (.))) %>%
  mutate(Noisy.Sepal.Length = Sepal.Length + 10.0*other_noise) %>%
  select(-other_noise)

```

Let's have a quick look at the resultant dataset on which I'll be using. The plots below may be overwhelming to start with but they are really useful. I've deliberately asked for data for different species to be plotted in different colours to help interpret the data as one of the things we're going to want to do is to classify species. I'll interpret them once I've plotted them.

```{r,  generate pairs plots of the augmented iris dataset, warning=FALSE, message=FALSE}
GGally::ggpairs(iris_n_noise, mapping = aes(color = Species))
```

There's a lot in this plot but in essence it compares each column against all other columns and presents the results in a couple of different ways. There's density plots on the diagonal, scatter-0plots below the diagonal and other useful statistics above the diagonal. I'll focus on the sub-plots that are most illustrative for the classification / regression problems:

-   **Guess the (classification of) Species:** The plots are coloured by the things we're trying to classify (Species). Red represents all "Setosa" plants, green are "Versicolor", and blue are "Virginica". The colouring makes it easy for us humans to find some goods ways to classify species based on other measurements. Looking at the plots along the row labelled Species, we can see ho species relates to the other variables. moving from left-to-right... The blue red and green visuals in "Sepal.Length" and "Sepal.Width" columns overlap horizontally showing that sometimes the various species have similar values for each. The "Petal" dimensions are much more different between the species. this means that knowing (for example) the "Petal.Length" tells you more about the species than (say) the "Sepal.Length". The last two columns ("Noise" and "Noisy.Sepal.Length") show reg green and blue plots overlapping which means that (as expected) knowing these values tells us almost nothing about the Species of the iris.
-   Estimating (regressing onto) the Length of petals: Regression relies on there being a clean relationship between one thing an another. So in this case we're looking for plots where the data is nicely spread along some kind of line or curve. Given a certain value of some other variable you can can look-up with reasonable confidence the length of the iris' petals. If you look at the scatter-plot on the column "Petal.Length" and row "Petal.Width" you can see the points lie nicely on a diagonal. this means that Petal.Width is probably a good things to use in regression model of Petal.Length. Contrast this with the the plot relating "Petal.Length" with "Noise". The points are all jumbled about, there's no line or curve whatsoever, so knowing the value of "Noise" can tells us very little about the Petal.Length. Any regression models should rely on Petal.Width considerably more than "Noise".

# Machine Learning and Excel

We're going to take the following steps to create Machine Learning models in Excel.

1.  Build the ML model (I'm using R, but you could do this just as easily in Python)

2.  translate the model into excel-friendly syntax

3.  Embed the model in Excel.

I hope you're not disappointed that I'm building the model outside excel and then "only" using the model inside excel. I guess you could do all this inside excel with the help of VBA but there are *many* more tool-sets in R and python for creating machine learning models. Playing to the strengths of each, let R or Python build the model, and let excel host the model.

## Slicing the iris dataset ready for Machine Learning

Machine Learning is powerful. It can generate all sorts of models encapsulating all sorts of relationships between this-and-that. That strength is also a weakness. We don't want to model *any* relationship, we want to model useful ones. As the famous statistician George Box said (almost 50 years ago)

> "All models are wrong but some are useful"
>
> -   George Box, 1976

The ML community has come up with many ways to ensure that these super-powerful data-driven models[^3] don't get carried away and dream up exotic relationships between this or that[^4]. I'm not going into any great detail here (and I may be cutting corners that should be cut) but all I'm going to do is to split the iris dataset into two.

[^3]: like random-forests, neural-networks and boosted trees etc

[^4]: complexity penalty functions, regularisation bootstrapping, (n-fold) cross validation are just a few

-   A training dataset: As there name implies, the training dataset is used to train the ML model. sometimes the training data is further split into training and validation. Where the former is used to defined the parameters of the model and the latter is held-out to check the model. The validation sets are used to stop the model "over fitting" (memorising) the input/output relationships of the training data and having little or no generalisability when presented with new data. Think of a student revising for a maths exam... They could learn the answer for some question (by rote) or the way in which the answer can be calculated. When we ask a ML system to learn something from data, more-often than not, we'd like to to capture some underlying relationship rather than be some look-up table.

-   A test dataset: The test dataset is withheld from the ML model so that the model's performance in general can be assessed. note: that validation dataset I mentioned in the training bullet above is analogous to this but *is* made available to the model when defining it's parameters.

So in this (folded) bit of code I'm splitting the dataset (roughly two-thirds, one-third) into training and test datasets. I'll use the former to train the models. the latter to test if the models should be any good on genuinely unseen data.

```{r keep a small section (about 30% of the iris data back to objectively see if the models are any good)}
df_split <- rsample::initial_split(iris_n_noise) # note: stratify by Species
df_train <- rsample::training(df_split)
df_test  <- rsample::testing(df_split)
```

As described earlier. random forests are made up of a (defined) set of decision trees. There are a few things we have control over when we're creating the forests. The most fundamental is to choose the number of trees in the forest. In this example I'm choosing to have 300 trees. There are objective ways to define good numbers for this and other hyper-parameters. remember we're heading for excel... eventually I want to move the trees into excel, so I don't want too many as each one will take up a column in my final spreassheet

```{r define teh number of trees we will be considering in each forest}
ntrees_clas_rf <- 3#00
ntrees_reg_rf <- 5#0
```

## Classification

### Building the classification model

```{r build a random foreast calssifier }
model_clas <- ranger::ranger(Species ~ ., # we're modelling Species as a function of everything
                     data = df_train, # modelling data held in iris_n_noise
                     num.trees = ntrees_clas_rf,
                     importance = "impurity" # I've added the optional impurity so I check variable importance later
)

model_clas
    

```

### Evaluating the classification model

We can see how good the model is by checking it's performance against that test set. In the table below the columns are the "true" species and the rows are the output of the model. it's pretty good, it gets only 2 out of 38 wrong. (about 5%). I'm sure we could do better than this, but I'm happy that this is "good enough" for use in this post and I'll move on. If you want to see how to optimise random forests, the internet is your friend, subjects to search for include class-imbalance, feature-engineering, cross-validation, hyper-parameter tuning etc.

```{r}
pred.iris <- stats::predict(model_clas, data = df_test)

table(df_test$Species, pred.iris$predictions)
```

### Inspecting the classification model

The ML models can be quite difficult to understand. Again, the ML community have built a range of tools to help us inspect / understand what the model is doing and what inputs it things is most important to generate it's outputs. The plot below shows the importance of the variables as far as this fitted random forest is concerned:

```{r explore what is important when trying to classify iris Species }
    #  the importance is here: model_clas$variable.importance
    model_clas %>% 
      vip::vip(num_features = 20,  aesthetics = list(color = "grey50", fill = "lightblue"))
```

The variable importance plot shows that the Petal width / height are much more valuable to know when trying to classify the species of an iris than (say) sepal dimensions, and even more valuable than those noisy measurements I added to the dataset which had little or no linkage with anything.

**Actionable insight:** The variable importance plots are valuable both to the model builder (to sense-check that the model is doing sensible things) and for the process of data collection and duration... Why collect (potentially buy) and store the noise variable if it is not adding significant value to out decision making process?

Caveat: take care when making value decisions. I would recommend testing model performance with / without the more exotic parameters in case they are rarely used, but super-valuable for some corner case that *must* be modelled well.

### The logic in the decision trees

As described earlier, I've built the classification model on a random forest made up of 300 different decision trees. each decision tree is a family of nested IF-THEN statements that look a bit like that scooby-doo meme that start all of this. We can inspect the contents of each tree, either as logic:

```{r one classification tree summarised as DPLYR syntax}
  as.character(tidypredict::tidypredict_fit(model_clas)[1]) # DPLYR
```

or even as SQL as shown below (note: SQL is really useful, we're going to push the decision trees into excel, but SQL can be pushed into databases so that the whole classification process can be done inside datasets too.).

```{r one classification tree summarised as SQL }
tidypredict::tidypredict_sql(model_clas, dbplyr::simulate_dbi())[1] # SQL
```

I've written a couple of functions that will take the logic formatted as SQL and turn it into something that can be run in Excel as shown below:

```{r a function to translate SQL CASE WHEN into excel friendly if statements}
# function to process the format returned by tidypredict_sql into
# a format that excel can parse
# sql_to_excel ----
sql_to_excel <- function(trees_df, input_df, n_sf = 3, squishit = T) {
  
  equations_in_cols_a <- trees_df %>%
    # adapt
    # the kinds of things you find output from tidypredict_sql
    mutate(instruction = str_replace_all(instruction, "AND", ",")) %>%
    mutate(instruction = str_replace_all(instruction, "CASE\nWHEN", "=IF(AND")) %>%
    mutate(n_parts = str_count(instruction, "\n"), .before = instruction) %>%
    mutate(instruction = str_replace_all(instruction, "WHEN", ", IF(AND")) %>%
    mutate(instruction = str_replace_all(instruction, "THEN", ", ")) %>%
    mutate(instruction = str_replace_all(instruction, "END", ", 'SHOULDNTHAPPEN'")) %>%
    #  mutate(instruction = str_replace_all(instruction, "\n", ", ")) %>%
    mutate(end = str_pad(string = "", width = n_parts, side = "right", pad = ")"), .after = n_parts) %>%
    mutate(output = paste0(instruction, end)) %>%
    mutate(output = str_replace_all(output, "'", '"')) %>%
    mutate(output = str_squish(output))
  
  # limit to a certain number of significant figures
  if(exists("n_sf")) {
    equations_in_cols_a <- equations_in_cols_a  %>%
      mutate(output = str_replace_all(output, "\\d+\\.\\d+", function(x) as.character(round(as.numeric(x), n_sf))))
  }
  
  # remove any unnecessary spaces that are only really there to aid the human eye
  if(squishit) {
    equations_in_cols_a <- equations_in_cols_a  %>%
      mutate(output = str_replace_all(output, " ", ""))
  }
  
  # we are going to swap references to the column names in R
  # with column names in excel (e.g. Sepal.Width becomes A[ROW_NUM])
  # we're adding [ROW_NUM] because later we're going to have many rows of calcs
  # substitute A[ROW_NUM], with A[1], A[2] etc.
  # this dataframe has two columns,  the R column name and the A/B/C etc for excel
  # we'll subsitute the R ones with th excel cols references later
  replacements <- names(input_df) %>%
    tolower() %>%
    enframe(name = NULL, value = "word") %>%
    mutate(col_letter = paste0(LETTERS[row_number()], "[ROW_NUM]"))

  # ultimately we'll be having one equation per column
  # for now there's one equation per row
  # we're going to want to labels them rule_1...rule_n
  # (these will be the col titles) in excel)
  # AND ...
  # we want to substitute the original variable names in the equations
  # with the correspondinh excel column references
  equations_in_cols <- equations_in_cols_a %>%
    # make a reference to the column names...
    mutate(tree_number = row_number()) %>%
    # unpack the (wide) equation into (long) parts so we can get at the variables
    tidytext::unnest_tokens(word, output, token = "regex", pattern = "`") %>%
    # we only need a couple of the columns going forwards
    select(tree_number, word) %>%
    # do a lookup find&replace using left_join
    left_join(replacements)

  # breakpoint in the pipeline here.. .I want to check that some of the
  # variables have been found
  # (i.e. we're not passing in a dataframe that doesnt have the same variables)
  if(nrow(equations_in_cols %>% filter(!is.na(col_letter))) <1) {
    warning("sql_to_excel: NO MATCHES IN replacements")
  } else {
    message("sql_to_excel: replacements found")
  }
  
  equations_in_cols <- equations_in_cols %>%
    # then coalesce, as this will sub-in col_letter is it's defined, and word if not
    mutate(new_word = coalesce(col_letter, word)) %>%
    # now we can repack the (long) parts of the equations into whole (wide) equation
    # grouping by tree_number will work on all the components of each equation in turn
    group_by(tree_number) %>%
    # summarise paste0 concatenates the rows into one (wide) reconstructed equation
    summarise(output = paste0(new_word, collapse = ''))
  
  #| transpose (flip) the array so that
  #| the equations are in columns rather than rows
  equations_in_rows <- equations_in_cols %>%
#    mutate(tree_number = paste0("tree_", tree_number)) %>%
    gather(key = var_name, value = value, 2:ncol(equations_in_cols)) %>% 
    spread(key = names(equations_in_cols)[1],value = 'value') %>%
    rename_with(~ paste0("tree_", .), -var_name) %>%
    select(-var_name)
  
  return(equations_in_rows)
} 

```

The function generates the following output for the tree we have been exploring:

```{r}
  #| random forest classification in excel format ----
tictoc::tic()
# tidypredict_sql takes a while (10s of seconds)
trees_df_clas <- tidypredict::tidypredict_sql(model_clas, dbplyr::simulate_dbi()) %>%
  tibble::enframe(name = NULL, value = "instruction") %>%
  mutate(instruction = unlist(instruction))
tictoc::toc()

randforest_clas <- sql_to_excel(trees_df = trees_df_clas, input_df = iris_n_noise)

randforest_clas$tree_1

```

**We're almost there!** The process of fitting Machine Learning models and praparing them to be used inside Excel is starting to come together. The above is the logic from just one of the 300 decision trees. Each of the other trees was trained on slightly different data and hence has captured slightly different logic, all trees are of value and must be translated and exported. When resolving different suggestions for species from different trees, the random forest algorithms can use voting methods like "most often suggested" to come up with a single final answer. If I'm to get this embedding into excel I will have to emulate that voting system too. See the section on getting the models into Excel for the rest of that story. For now I'll move on to regression.

## Regression

I'm re-using the iris dataset to explore regression. In this section, instead of having the Species as a target variable, I'm going to model Petal Length. I'll be making available all the other stuff I know about each iris to the learning systems. They will pick and chose which variables are important and how they should be combined to give me an way of estimating how long my iris petals might be given all that other information.

Random forests are a for of ML that can do both classification AND regression. This is great because *most* of what I've written, and you've read from the classification section remains true[^5].

[^5]: In the implementation of random forests I'm using, the bit that translates each tree into SQL doesn't handle categorical variables very elegantly. It translates them into counting numbers, so the iris class becomes 1, 2 &3. not a huge issue, but I would've rather it have captured the categorical input data as elegantly as the LM clearly does (read on)

Before diving in to random forests for regression I thought I'd have a quick look at a more traditional way of building models.... Linear regression.

### Regression using LM (Linear models)

First off, I'd just like to state that linear models and generalised linear models *are* a form of machine learning. They generate information from data. I'm deliberately(ish) adding this section on regression in LMs because they are more familiar to many than other ML techniques and act as a valuable reference point against which other ML techniques can be compared. And yes, I appreciate that Excel already has capability to do linear regression, but I'm trying to highlight bridges here, one step beyond preparing the data to be fitted in excel is doing the fit elsewhere and feeding the fitted model into Excel for on-use.

Fitting linear models in R and checking the significance of each parameter is really easy

```{r}
model_lm <- lm(Petal.Length ~ ., data=df_train)
model_lm %>%
    broom::tidy() %>% arrange(p.value)
```

Refining the model to only include useful stuff can be don by forward steo-wise variable selection (select & backward elimination)

```{r}
simplified_model <- MASS::stepAIC(model_lm, direction = "both")
# have a look at this model 
simplified_model %>%
  broom::tidy() %>% arrange(p.value)

```

which results in simpler models (which could be further refined). Notice that som.

The model that has been allowed to add & remove variables is simpler and better than the model forced to use all of the variables

```{r}
performance::compare_performance(model_lm, simplified_model, rank = TRUE)

```

we can check how well the model performs

```{r}
library(ggpubr)
df_test %>%
  as_tibble() %>%
  nest(data = everything()) %>%
  mutate(full_model = list(model_lm)) %>% 
  mutate(full_prediction = map2(full_model, data, ~broom::augment(.x, newdata = .y))) %>%
  unnest(full_prediction) %>%
  rename(full_prediction = .fitted) %>%
  select(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, Species, Noise, Noisy.Sepal.Length, full_prediction) %>%
  left_join(
    df_test %>%
      as_tibble() %>%
      nest(data = everything()) %>%
      mutate(simplified_model = list(simplified_model)) %>% 
      mutate(simplified_prediction = map2(simplified_model, data, ~broom::augment(.x, newdata = .y))) %>%
      unnest(simplified_prediction) %>%
      rename(simplified_prediction = .fitted) %>%
      select(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, Species, Noise, Noisy.Sepal.Length, simplified_prediction)
  ) %>%
  select(Petal.Length, Species, full_prediction, simplified_prediction) %>%
  pivot_longer(-c(Petal.Length, Species), names_to = "model", values_to = "estimate") %>%
  ggplot(aes(Petal.Length, estimate)) +
  geom_point(aes(colour = Species)) +
  stat_regline_equation(aes(label =  paste(after_stat(eq.label), after_stat(adj.rr.label), sep = "~~~~"))) +
  geom_smooth(method = "lm") +
  facet_wrap( ~ model)

```

The model can be turned into something that looks like R:

```{r}
  tidypredict::tidypredict_fit(simplified_model)
```

and translate the model into something that looks more like something Excel would recognise

```{r}
#' @title fit_to_excel
#'
#' @description
#' This function converts a string as outputted by tidymodels::tidypredict_fit()
#' and returns something that model like an excel formula
#' the result includes variable (column) names,  not cell references
#' @param trees_df a 1D df containing one row per model
#' @param input_df The dataframe upon which the model is to be used
#' @param n_sf number of significant figures (parameters are rounded to save space)
#' @param squishit should extra whitespace be removed to save space
#'
#' @return a dataframe with the reformatted equation(s) in rows
#'
#' @export
#'
fit_to_excel <- function(trees_df, input_df, n_sf = 3, squishit = T) {
  
  equations_in_cols_a <- trees_df %>%
    # adapt
    # the kinds of things you find output from tidypredict_fit
    mutate(output = instruction) %>%
    mutate(output = str_replace_all(output, "ifelse", "if")) %>%
    mutate(output = str_replace_all(output, "==", "=")) %>%
    mutate(output = str_squish(output))
  
  # limit to a certain number of significant figures
  if(exists("n_sf")) {
    equations_in_cols_a <- equations_in_cols_a  %>%
      mutate(output = str_replace_all(output, "\\d+\\.\\d+", function(x) as.character(round(as.numeric(x), n_sf))))
  }
  
  # remove any unnecessary spaces that are only really there to aid the human eye
  if(squishit) {
    equations_in_cols_a <- equations_in_cols_a  %>%
      mutate(output = str_replace_all(output, " ", "")) %>%
      mutate(output_as_excel = "") # im adding this so I can check works been done
  }
  
  # we are going to swap references to the column names in R
  # with column names in excel (e.g. Sepal.Width becomes A[ROW_NUM])
  # we're adding [ROW_NUM] because later we're going to have many rows of calcs
  # substitute A[ROW_NUM], with A[1], A[2] etc.
  # this dataframe has two columns,  the R column name and the A/B/C etc for excel
  # we'll subsitute the R ones with th excel cols references later
  replacements <- names(input_df) %>%
    enframe(name = NULL, value = "word") %>%
    mutate(col_letter = paste0(LETTERS[row_number()], "[ROW_NUM]"))
  
  # ultimately we'll be having one equation per column
  # for now there's one equation per row
  # we're going to want to labels them rule_1...rule_n
  # (these will be the col titles) in excel)
  # AND ...
  # we want to substitute the original variable names in the equations
  # with the corresponding excel column references
  # stack exchange to the rescue:
  # https://stackoverflow.com/questions/50750266/r-find-and-replace-partial-string-based-on-lookup-table
  for(i in 1:nrow(equations_in_cols_a)) {
    orig_row <- equations_in_cols_a[i,]$output
#    print(as.character(row))
    updated_row <- stringi::stri_replace_all_fixed(orig_row, replacements$word, replacements$col_letter, vectorize_all=FALSE)
#    print(row)
    equations_in_cols_a[i,]$output_as_excel <- updated_row
  } 
  if( nrow(equations_in_cols_a %>% filter(output == output_as_excel)) ) {
    warning("fit_to_excel: NO MATCHES IN replacements")
  } else {
    message("fit_to_excel: replacements found")
  }
  
  equations_in_cols <- equations_in_cols_a %>%
    transmute(output = output_as_excel) %>%
    mutate(tree_number = row_number(), .before = 1)
  #| transpose (flip) the array so that
  #| the equations are in columns rather than rows
  equations_in_rows <- equations_in_cols %>%
    select(output) %>%
    mutate(tree_number = row_number(), .before = 1) %>%
    gather(key = var_name, value = value, 2:ncol(equations_in_cols)) %>% 
    spread(key = names(equations_in_cols)[1],value = 'value') %>%
    rename_with(~ paste0("tree_", .), -var_name) %>%
    select(-var_name)
  
  return(equations_in_rows)
} #
  # this emulates LM in excel format ----
  trees_df_lm <- tidypredict::tidypredict_fit(model_lm)[2] %>% as.character() %>%
    tibble::enframe(name = NULL, value = "instruction") %>%
    mutate(instruction = unlist(instruction)) %>%
    mutate(instruction = as.character(instruction))
  
lm_excel <- fit_to_excel(trees_df = trees_df_lm, input_df = iris_n_noise, n_sf = 3)
lm_excel
```

### Regression using ML (Machine Learning)

As stated previously, random forests can be used for both classification and regression tasks with very little modification. Regression random forests can have bigger trees with mode leaves, and the suggestions from all the individual trees are reconciled by using averages rather than the majority voting method described for classification, but most of the mechanics remain unaltered when using them for regression.

I'm going to make one minor modification to the Iris dataset before feeding it into the random forest for regression. I'm going to change the way that "Species" is encoded. I'll change it from three words, to three numbers. This is the only compromise I'm making in this blog and I'm going do because I'm relying on a third-party routine (tidtpredict::tidypredict_sql) to flatten the decision tree rules and convert them into SQL. this routine returns the logic for factors (like Species) as numbers, so it's easier for me to turn them into numbers at the outset than handle the mapping when I get the SQL. The code to re-map the species is shown below:

```{r converting species from factor to integer (I dont like having to do this) }
iris_n_noise_reg <- iris_n_noise %>%
  mutate(Species = as.integer(Species))
# As before, the avoid over-fitting,  I'll split the regression dataset into training and testing datasets. First I'll split the data into two (one set is something I can use to train the model,  the other I will keep in reserve to test the model.  Then, I will build a 10-fold cross-validation dataset from training dataset. This sounds fancy, but it's just creating 10 alternative takes on the iris dataset by sampling (with replacement) from the initial one. All 10 folds contain examples drawn from the iris dataset, but each fold will contain a different mix of examples

set.seed(037)
iris_reg_split <- rsample::initial_split(iris_n_noise_reg, strata = Petal.Length)
iris_reg_train <- rsample::training(iris_reg_split)
iris_reg_test  <- rsample::testing(iris_reg_split)
```

Now I can build the random forest. I could use ranger directly as follows:

```{r decision tree regression directly using ranger}

# we're modelling Species as a function of everything...
model_reg <- ranger::ranger(Petal.Length ~ ., 
                    data = iris_reg_train, 
                    num.trees = ntrees_reg_rf,
                    # I've added the optional impurity
                    # so I check variable importance later
                    importance = "impurity" 
)

```

plot the model's performance:

```{r scatterplot of simple ranger model }
# then do a quick check on teh output
pred.iris <- stats::predict(model_reg, data = iris_reg_test)
bind_cols(iris_reg_test$Petal.Length, pred.iris$predictions) %>%
  rename(actual = ...1, pred = ...2) %>%
  ggplot(aes(actual, pred)) +
  geom_point() +
  stat_regline_equation(aes(label =  paste(after_stat(eq.label), after_stat(adj.rr.label), sep = "~~~~"))) + 
  geom_smooth(method = "lm") +
  geom_abline(slope = 1, intercept = 0)

```

check what variables are considered important in this model:

```{r variable importance in the 1st go of ML RF model }
model_reg %>%
      vip::vip(num_features = 20,  aesthetics = list(color = "grey50", fill = "lightblue"))
```

Then carry on having extracted the rules as per the classification example. See below for a single tree that's been fitted in the random forest. Notice that the tree is considerably larger than the one we explored in the classification case.

```{r example of a complicated rule (one of n)}

tidypredict::tidypredict_sql(model_reg, dbplyr::simulate_dbi())[1]

```

## Getting the models into Excel

### A couple of utility functions

```{r  utlility functions to help reformat teh RF rules and add them to df}

#' @title add.formula
#'
#' @description
#' decorates a column in a dataframe with 'formula'
#' doingf this makes excelk evaluate the contents rather than just
#' treating them as a string and presenting the formaula rather than its result
#' thanks here to: https://stackoverflow.com/questions/45579287/r-assign-class-using-mutate
add.formula <- function(x) {class(x) <- c(class(x), "formula"); x}

#' @title add.formula
#'
#' @description
#' things function returns the letter of a column index by x in excel format
#' Excel has a col::row reference system with letters::numbers
#' the letters (columns) starft at 'A',  continue until 'Z' then 'AA'-'ZZ'
#' 
#' @param x the columns number (starting from 1 -> 'A')
#'
#' @return string containing the excel letter-based column reference 
#' 
get_excel_letter <- function(x) {
  paste0(LETTERS[((x-1) %/% 26)], LETTERS[1+((x-1) %% 26)])
}

#' @title sql_to_excel
#'
#' @description
#' This function converts a string as outputted by tidymodels::tidypredict_sql()
#' and returns something that model like an excel formula
#' the result includes variable (column) names,  not cell references
#' @param trees_df a 1D df containing one row per model
#' @param input_df The dataframe upon which the model is to be used
#' @param n_sf number of significant figures (parameters are rounded to save space)
#' @param squishit should extra whitespace be removed to save space
#'
#' @return a dataframe with the reformatted equation(s) in rows
#'
#' @export
#'
sql_to_excel <- function(trees_df, input_df, n_sf = 3, squishit = T) {
  
  equations_in_cols_a <- trees_df %>%
    # adapt
    # the kinds of things you find output from tidypredict_sql
    mutate(instruction = str_replace_all(instruction, "AND", ",")) %>%
    mutate(instruction = str_replace_all(instruction, "CASE\nWHEN", "=IF(AND")) %>%
    mutate(n_parts = str_count(instruction, "\n"), .before = instruction) %>%
    mutate(instruction = str_replace_all(instruction, "WHEN", ", IF(AND")) %>%
    mutate(instruction = str_replace_all(instruction, "THEN", ", ")) %>%
    mutate(instruction = str_replace_all(instruction, "END", ", 'SHOULDNTHAPPEN'")) %>%
    #  mutate(instruction = str_replace_all(instruction, "\n", ", ")) %>%
    mutate(end = str_pad(string = "", width = n_parts, side = "right", pad = ")"), .after = n_parts) %>%
    mutate(output = paste0(instruction, end)) %>%
    mutate(output = str_replace_all(output, "'", '"')) %>%
    mutate(output = str_squish(output))
  
  # limit to a certain number of significant figures
  if(exists("n_sf")) {
    equations_in_cols_a <- equations_in_cols_a  %>%
      mutate(output = str_replace_all(output, "\\d+\\.\\d+", function(x) as.character(round(as.numeric(x), n_sf))))
  }
  
  # remove any unnecessary spaces that are only really there to aid the human eye
  if(squishit) {
    equations_in_cols_a <- equations_in_cols_a  %>%
      mutate(output = str_replace_all(output, " ", ""))
  }
  
  
  # we are going to swap references to the column names in R
  # with column names in excel (e.g. Sepal.Width becomes A[ROW_NUM])
  # we're adding [ROW_NUM] because later we're going to have many rows of calcs
  # substitute A[ROW_NUM], with A[1], A[2] etc.
  # this dataframe has two columns,  the R column name and the A/B/C etc for excel
  # we'll subsitute the R ones with th excel cols references later
  replacements <- names(input_df) %>%
    tolower() %>%
    enframe(name = NULL, value = "word") %>%
    mutate(col_letter = paste0(LETTERS[row_number()], "[ROW_NUM]"))

  # ultimately we'll be having one equation per column
  # for now there's one equation per row
  # we're going to want to labels them rule_1...rule_n
  # (these will be the col titles) in excel)
  # AND ...
  # we want to substitute the original variable names in the equations
  # with the correspondinh excel column references
  equations_in_cols <- equations_in_cols_a %>%
    # make a reference to the column names...
    mutate(tree_number = row_number()) %>%
    # unpack the (wide) equation into (long) parts so we can get at the variables
    tidytext::unnest_tokens(word, output, token = "regex", pattern = "`") %>%
    # we only need a couple of the columns going forwards
    select(tree_number, word) %>%
    # do a lookup find&replace using left_join
    left_join(replacements)

  # breakpoint in the pipeline here.. .I want to check that some of the
  # variables have been found
  # (i.e. we're not passing in a dataframe that doesnt have the same variables)
  if(nrow(equations_in_cols %>% filter(!is.na(col_letter))) <1) {
    warning("sql_to_excel: NO MATCHES IN replacements")
  } else {
    message("sql_to_excel: replacements found")
  }
  
  equations_in_cols <- equations_in_cols %>%
    # then coalesce, as this will sub-in col_letter is it's defined, and word if not
    mutate(new_word = coalesce(col_letter, word)) %>%
    # now we can repack the (long) parts of the equations into whole (wide) equation
    # grouping by tree_number will work on all the components of each equation in turn
    group_by(tree_number) %>%
    # summarise paste0 concatenates the rows into one (wide) reconstructed equation
    summarise(output = paste0(new_word, collapse = ''))
  
  #| transpose (flip) the array so that
  #| the equations are in columns rather than rows
  equations_in_rows <- equations_in_cols %>%
#    mutate(tree_number = paste0("tree_", tree_number)) %>%
    gather(key = var_name, value = value, 2:ncol(equations_in_cols)) %>% 
    spread(key = names(equations_in_cols)[1],value = 'value') %>%
    rename_with(~ paste0("tree_", .), -var_name) %>%
    select(-var_name)
  
  return(equations_in_rows)
} 
#usage:
# theRes <- sql_to_excel(trees_df_clas, iris)
# theRes["tree_1"]

#' @title augment_df_with_rules
#'
#' @description
#' This function takes a list of models (e.g. a LM, or many decision trees)
#' and transforms them so that they act on the "in_df" as per excel
#' @param models a 1D df containing one row per model
#' @param in_df The dataframe upon which the model is to be used
#' @param target The names of the target variable (must be in the in_df)
#' @param method classification or regression (this affects how trees are agregated)
#'
#' @return a character string with the "html" class and "html" attribute
#'
#' @export
#'
#' @examples
#' asHTML("<p>This is a paragraph</p>")
#'
augment_df_with_rules <- function(models, in_df, target = NA, method = "classification") {
  # were' going to insert a few stats cols after the input data so
  # the start of the trees will be at this column:
  nstats <- 3 # I'm adding 3 extra columns (best, confidence and match)
  index_of_target <- which(names(in_df) == target)
  if(length(index_of_target)==0) {
    stop("augment_df_with_rules: target (", target, ") could not be found")
  }
  trg_col <- get_excel_letter(index_of_target) # this is where thhe target is in the dataset
  trg_ref_col <- get_excel_letter(ncol(in_df)+1) # this the  target copied into the end of the dataset
  mod_col <- get_excel_letter(ncol(in_df)+2) # this is the col of the best model
  first_model_col <- get_excel_letter(ncol(in_df)+nstats+2) # start of options for model output
  last_model_col  <- get_excel_letter(ncol(models)+ncol(in_df)+nstats+1) # end of options for model output

  result_df <- in_df %>%
    as_tibble() %>%
    bind_cols(models)
  
  if(method == "classification") {
    result_df <- result_df %>%
      mutate(tree_target = glue::glue("={trg_col}[ROW_NUM]"), .before = tree_1) %>%
      mutate(tree_best = glue::glue("=INDEX({first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM], MODE(MATCH({first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM], {first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM], 0 )))"), .before = tree_1) %>%
      mutate(tree_confidence = glue::glue("=COUNTIF({first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM], {trg_ref_col}[ROW_NUM]) / COUNTA({first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM])"), .before = tree_1) %>%
      mutate(tree_match = glue::glue("={mod_col}[ROW_NUM]={trg_ref_col}[ROW_NUM]"), .before = tree_1)
  } else {
    result_df <- result_df %>%
      mutate(tree_target = glue::glue("={trg_col}[ROW_NUM]"), .before = tree_1) %>%
      mutate(tree_best = glue::glue("=AVERAGE({first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM])"), .before = tree_1) %>%
      mutate(tree_confidence = glue::glue("=1-SQRT(VAR({first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM], {trg_ref_col}[ROW_NUM])) / AVERAGE({first_model_col}[ROW_NUM]:{last_model_col}[ROW_NUM])"), .before = tree_1) %>%
      mutate(tree_match = glue::glue("=({mod_col}[ROW_NUM]-{trg_ref_col}[ROW_NUM])/{trg_ref_col}[ROW_NUM]"), .before = tree_1)
  }
  
  result_df <- result_df %>%
    mutate(row_num = as.character(row_number()+1)) %>% # +1 because in excel there's a title in row 1
    # fold in the actual row number instead of that place holder "ROW_NUM"
    mutate_at(vars(starts_with("tree")), list(~ str_replace_all(., "\\[ROW_NUM\\]", row_num))) %>%
    # decorate the calculation columns as formula so excel will show the results rather than the equations
    mutate_at(vars(starts_with("tree")), add.formula) %>%
    select(-row_num)
  
  return(result_df)
}

```

### preparing the models for export to excel

```{r prepping the models to be understandable in excel }

  #| turn the tidypredict_sql for all the trees into a tidy dataframe

  #| random forest classification in excel format ----
  trees_df_clas <- tidypredict::tidypredict_sql(model_clas, dbplyr::simulate_dbi()) %>%
    tibble::enframe(name = NULL, value = "instruction") %>%
    mutate(instruction = unlist(instruction))

  randforest_clas <- sql_to_excel(trees_df = trees_df_clas, input_df = iris_n_noise)
  model_output_clas <- augment_df_with_rules(models = randforest_clas,
                                             in_df = iris_n_noise,
                                             target = "Species",
                                             method = "classification")
  trees_df_clas[1,]
  model_output_clas[1,"tree_1"]

  # this emulates LM in excel format ----
  trees_df_lm <- tidypredict::tidypredict_fit(model_lm)[2] %>% as.character() %>%
    tibble::enframe(name = NULL, value = "instruction") %>%
    mutate(instruction = unlist(instruction)) %>%
    mutate(instruction = as.character(instruction))
  # make excel-friendly
  lm_excel <- fit_to_excel(trees_df = trees_df_lm, input_df = iris_n_noise, n_sf = 3)
  model_output_lm <- augment_df_with_rules(models = lm_excel,
                                           in_df = iris_n_noise,
                                           target = "Petal.Length",
                                           method = "regession")
  
  
  if(F) {
    xgboost_excel <- sql_to_excel(trees_df = trees_df_xgboost_reg, input_df = iris_n_noise)
    model_output_xgboost <- augment_df_with_rules(models = xgboost_excel, in_df = iris_n_noise, method = "regession")
    # doesnt work yet as the "or(A3isnull)" in trees_df_xgboost_reg SQL bits arent parsed correctly YET
  }
  
  # random forest regression in excel format ----
  # get the rules
  trees_df_iris_reg <- tidypredict::tidypredict_sql(model_reg, dbplyr::simulate_dbi()) %>%
    tibble::enframe(name = NULL, value = "instruction") %>%
    mutate(instruction = unlist(instruction)) 
  # convert the rules to excel format 
  randforest_reg <- sql_to_excel(trees_df = trees_df_iris_reg, input_df = iris_n_noise)
  dim(randforest_reg) #one row but many columns (one per tree)
  model_output_iris_reg <- augment_df_with_rules(models = randforest_reg,
                                                 in_df = iris_n_noise,
                                                 target = "Petal.Length",
                                                 method = "regression")
  
  dim(model_output_iris_reg) # many rows (one per example) and many columns (one per tree)
  model_output_iris_reg[1,]$tree_best
  model_output_iris_reg[1,]$tree_confidence
  model_output_iris_reg[1,]$tree_match
  # example rule
  model_output_iris_reg[1,]$tree_1
  # the trees can be quite long as every condition is defined as "IF",
  # most of the conditions for the next case are really just "ELSE"
  # but this way makes things much easier to read as a human
  # excel's nested if(this, that, if(other...)) quickly become impenetrable
  str_length(model_output_iris_reg[1,"tree_1"])

```

sdfdfgsdfg

### creating excel spreadsheet

It's easy to create an excel workbook with multiple tabs, one for each example I created above:

```{r create the excel spreadsheet }
  message("Creating excel workbook...")  
  output_wb <- openxlsx::createWorkbook(creator = "Leo Kiernan", subject = paste0("Ranger random forest model ", lubridate::now()))
  openxlsx::addWorksheet(output_wb, "README", tabColour = "blue")
  openxlsx::addWorksheet(output_wb, "lm", tabColour = "green")
  openxlsx::addWorksheet(output_wb, "lmRules", tabColour = "green")
  openxlsx::addWorksheet(output_wb, "regression", tabColour = "red")
  openxlsx::addWorksheet(output_wb, "regressionRules", tabColour = "red")
  openxlsx::addWorksheet(output_wb, "classification", tabColour = "orange")
  openxlsx::addWorksheet(output_wb, "classificationRules", tabColour = "orange")
  
  message("Populating excel workbook...")  
  
  tribble(
    ~from, ~tab, ~info,
    "LAK", "README", "This sheet",
    "LAK", "lm", "example of a regression using a linear model",
    "LAK", "lmRules", "example of the internal equations in the linear model",
    "LAK", "classification", "example of a classification random forest",
    "LAK", "classificationRules", "example of one rule from the classification random forest",
    "LAK", "regression", "example of a regression random forest",
    "LAK", "regressionRules", "example of one rule from the regression random forest"
  ) %>%
    mutate(Date = lubridate::now(), .before = 1) %>%
    openxlsx::writeDataTable( wb = output_wb,
                              sheet = "README",
                              x = .,
                              startCol = 1,
                              startRow = 1,
                              tableStyle = "TableStyleLight9",
                              tableName = "README")
  
  # lm ----
  model_output_lm %>%
    openxlsx::writeDataTable( wb = output_wb,
                              sheet = "lm",
                              x = .,
                              startCol = 1,
                              startRow = 1,
                              tableStyle = "TableStyleLight9",
                              tableName = "lm")
  
  trees_df_lm  %>%
    openxlsx::writeDataTable( wb = output_wb,
                              sheet = "lmRules",
                              x = .,
                              startCol = 1,
                              startRow = 1,
                              tableStyle = "TableStyleLight9",
                              tableName = "lmRules")

  # classification tree ----
  model_output_clas %>%
    openxlsx::writeDataTable( wb = output_wb,
                              sheet = "classification",
                              x = .,
                              startCol = 1,
                              startRow = 1,
                              tableStyle = "TableStyleLight9",
                              tableName = "classification")
  
  trees_df_clas  %>%
    openxlsx::writeDataTable( wb = output_wb,
                              sheet = "classificationRules",
                              x = .,
                              startCol = 1,
                              startRow = 1,
                              tableStyle = "TableStyleLight9",
                              tableName = "classificationRules")

  # regression tree ----
  model_output_iris_reg %>%
    openxlsx::writeDataTable( wb = output_wb,
                              sheet = "regression",
                              x = .,
                              startCol = 1,
                              startRow = 1,
                              tableStyle = "TableStyleLight9",
                              tableName = "regression")
  trees_df_iris_reg  %>%
    openxlsx::writeDataTable( wb = output_wb,
                              sheet = "regressionRules",
                              x = .,
                              startCol = 1,
                              startRow = 1,
                              tableStyle = "TableStyleLight9",
                              tableName = "regressionRules")
  
  
  message("Saving excel workbook...")  
  openxlsx::saveWorkbook(wb = output_wb,
                         file = here::here(stringr::str_c("posts/ML_in_excel/ml_in_excel.xlsx")),
                         overwrite = T)
  
  message("Done")

```

# Summary

dfg

# Appendix 1: hyper-parameter tuning for Random Forests

This section is about tuning hyper-parameters to get the best out of random Forests (or other ML techniques)

Spoiler alert: The regression task using the iris dataset seems to be simple enough to make even an un-tuned random forest quite good. The tuned models output at the end of this section is not really better than the one that I "threw together" in the main body of this post. **However** in general it is well worth exploring the impact of the choice of hyper-parameters.

Instead of directly using ranger in regression, I'm going to take a lead from [Julia Silge's post on tuning random forests](https://juliasilge.com/blog/sf-trees-random-tuning/) and use ranger indirectly inside another great package than is well worth exploring if you want to mode in R. It's called "tidymodels" and has a number of benefits including:

1.  Standardising the interface of many kinds of machine learning models (called "engines"). There's [a long and seachable list here](https://www.tidymodels.org/find/parsnip/))

2.  Tidy models allow data analysis pipelines to be constructed that use ML model "engines"

3.  Benefits 1 and 2 include the ability to swap or compare different ML engines with minimal effort.

I'll be using tidy models to do some "hyper-parameter" tuning. Tuning the following:

-   mtry : The number of predictors that will be randomly sampled at each split when creating the tree models.

-   min_n: The minimum number of data points in a node that are required for the node to be split further.

-   trees: The number of trees contained in the ensemble. Note: I'm deliberately not tuning this in the post and fixing this to 50 in the example as the trees can be quite large.

```{r load extra libraries}

library(tidypredict)
library(tidymodels)
library(parsnip)
library(recipes)
```

```{r run many models to explore the hyper-paramenter search space}
#
#| I want to run these models on as many cores as possible
#| That way the results come back sooner.
#| I've got a choice...
#|  I can totally max-out the coresdedicated to this task
#|   as per https://www.tidymodels.org/start/case-study/
cores <- parallel::detectCores()
#|    OR I can leave some that might be being used elsewhere
#|    as per: https://www.jottr.org/2022/12/05/avoid-detectcores/
#| Note: these may well be the same number if nothing el;se is running
# cores <- parallelly::availableCores()
# message(glue::glue("Running in parallel on {cores} availableCores rather than {parallel::detectCores()} detectCores"))

# INITIALISE: create 10 alternative versions of the training dataset
(iris_reg_train_folds <- rsample::vfold_cv(iris_reg_train))

# part 1: building data transformation pipeline (minimal)
rf_recipe <-recipe(Petal.Length ~ ., data = iris_reg_train)

# part 2: building model form (ranger regession)
rf_mod <- rand_forest(mtry = tune(), # anything with tune() will be searched
              min_n = tune(),
               # deliberately tiny forest as I just want to prove a point
              # if we were to tune this it would chose about 1000 trees
              trees = 50
              ) %>% 
  set_engine("ranger") %>% 
  set_mode("regression")

# part 3: construct the full workflow with the model & recipe
rf_workflow <- workflow() %>% 
  add_recipe(rf_recipe) %>%
  add_model(rf_mod) 

doParallel::registerDoParallel()

set.seed(37)
message("tuning the hyper-parameters using tune_grid...")
rf_res <- tune_grid(
  rf_workflow,
  resamples = iris_reg_train_folds,
  grid = 20,
  control = control_grid(save_pred = TRUE),
  metrics = metric_set(rmse, rsq, mae)
)

```

We could check if the seems to perform better for any given range of hyper-parameters...

```{r are there any trends in performance based on the choice of hyper-parameters}
message("Hyper parameter parameter sensitivity:")
tuned_grid_results <- rf_res %>%
  collect_metrics() %>%
#  filter(.metric == "rmse") %>%
  select(mean, .metric, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  )

tuned_grid_results %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
#  expand_limits(y = 0) +
  facet_grid(.metric~parameter, scales = "free") +
  labs(title = "Searching for really good settings on which to train the Random Forest",
       subtitle = "10-25 points per node (min_n) and 2-5 predictors (mtry) look promising",
       x = "parameter value",
       y = "Metric")
```

It looks like a goo5 choice of min_n (number of data-points in a node before you split it further) is somewhere between 10 & 20. The results look less sensitive to mtry (number of predictors to select for each tree) but let's make a grid around the centre of the most promising values.

```{r create a mode detailed fixed grid of values for the hyper-parameters}
rf_grid <- grid_regular(
  min_n(range = c(10, 25)),
  mtry(range = c(2, 5)),
  levels = 5
)

rf_grid
```

The retrain using the hyper-parameters zoomed in on that part of the hyper-parameter space

```{r  build a family of models based on the gridded hyper-parameters}
set.seed(37)
regular_res <- tune_grid(
  rf_workflow,
  resamples = iris_reg_train_folds,
  grid = rf_grid,
  metrics = metric_set(rmse, rsq, mae)
)
```

and plot the impact of the hyper-parameters again:

```{r plot the performance of the models against ther grid}
regular_res %>%
  collect_metrics() %>% 
#  filter(.metric == "rmse") %>%
  select(mean, .metric, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>% 
  mutate(value = as.factor(value)) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_boxplot(show.legend = FALSE) +
#  expand_limits(y = 0) +
  facet_grid(.metric~parameter, scales = "free") +
  labs(title = "Looking more closely at the hyper-parameters",
       subtitle = "It looks like small min_n & 3-4 predictors (mtry) is a good choice",
       x = "parameter value",
       y = "Metric")
```

We can let tidy models choose the best and extract the best model and then inspect what those hyper-parameters (min_n & mtry() turned out to be

```{r get the best model}
message("Extracting the best model")
rf_best <- 
  regular_res %>% 
  select_best(metric = "rmse")

# the last regression model ----
message("starting again but this time using the best hyper-parameters...")
last_rf_mod <- 
  rand_forest(mtry = rf_best$mtry, min_n = rf_best$min_n, trees = ntrees_reg_rf) %>% 
  set_engine("ranger", num.threads = cores, importance = "impurity") %>% 
  set_mode("regression")

# the last workflow
message("updating the workflow to include the chosen model form")
last_rf_workflow <- 
  rf_workflow %>% 
  update_model(last_rf_mod)

set.seed(37)
last_rf_fit <- 
  last_rf_workflow %>% 
  last_fit(iris_reg_split) # cores

last_rf_fit

last_rf_fit %>% 
  collect_metrics()

message("Collect the final model")
final_model_reg <- last_rf_fit %>% 
  extract_fit_parsnip()

```

What variables does this model depend on most?

```{r variable importance of optimised model}
final_model_reg %>%
      vip::vip(num_features = 20,  aesthetics = list(color = "grey50", fill = "lightblue"))
```

Have a look at how good the regression is

or like this:

```{r}
# First, get the processed version of the test set predictors:
iris_reg_test %>%
  bind_cols(
    predict(final_model_reg, new_data = iris_reg_test)
  ) %>%
  ggplot(aes(x = Petal.Length, y = .pred)) +
    stat_regline_equation(aes(label =  paste(after_stat(eq.label), after_stat(adj.rr.label), sep = "~~~~"))) + 
  geom_smooth(method = "lm") +
  geom_point() +
  labs(title = "The estimates of Petal Length from Random Forest looks good",
       subtitle = "This model is the one selected after hyper-parameter tuning",
       X = "Observed Petal Length (mm)", 
       y = "Modelled Petal Length (mm)")

```

The model plotted above looks pretty good but it's not really any better than the simple ranger one we build at the very start of this section. The keen eye will notice that there's a cluster of point in the bottom left of the plot that look quite flat. These are the Petal Lengths from "Setosa" species. we could revisit the model for and allow interactions between other variables and Species to further improve the model fit, but we're trying to get the models into Excel so it's time to move on from the process of generating the models.

```{r session info}

sessioninfo::session_info()
```
